# Projeto-4-An√°lise de Churn

# üìä Projeto: An√°lise de Evas√£o de Clientes (Churn Analysis)

## üìù Introdu√ß√£o

Este projeto tem como objetivo identificar os principais fatores que levam √† evas√£o de clientes (churn) em um banco com opera√ß√µes na Alemanha, na Espanha e na Fran√ßa, utilizando t√©cnicas de machine learning e an√°lise explorat√≥ria de dados com o intuito de formular pol√≠ticas que aumentem a reten√ß√£o dos clientes mais propensos a desistir dos servi√ßos do banco e, dessa forma, minimizar o impacto financeiro gerado pelo churn.

---

## üìä Dados

Foram utilizados dados contendo informa√ß√µes cadastrais e transacionais dos clientes, incluindo vari√°veis como **idade**, **saldo**, **sal√°rio estimado**, **produtos contratados** e se o cliente deixou ou n√£o a institui√ß√£o **(vari√°vel alvo: `Exited`)**.

### Etapas realizadas:
- Importa√ß√£o do dataset `Churn_treino.csv` com separador `;`
- An√°lise da distribui√ß√£o da evas√£o por **localiza√ß√£o geogr√°fica**, **idade** e **g√™nero**
- Verifica√ß√£o e tratamento de valores faltantes
- Codifica√ß√£o de vari√°veis categ√≥ricas com `LabelEncoder`
- Padroniza√ß√£o de vari√°veis num√©ricas com `StandardScaler`
- Balanceamento da base utilizando **SMOTE** para lidar com desbalanceamento da vari√°vel alvo

---

## ü§ñ Modelagem Preditiva

Modelos aplicados:
- Rede Neural (Keras)
- Regress√£o Log√≠stica
- Random Forest
- Naive Bayes
- SVM
- AdaBoost
- XGBoost
- KNN
- LightGBM

Todos os modelos foram treinados com `train_test_split` e avaliados de acordo com as m√©tricas **acur√°cia**, **precis√£o**, **recall** e **F1-score**.
---

## üîç Principais Insights

- Clientes mais velhos tendem a evadir com mais frequ√™ncia.
- Clientes do pa√≠s **‚ÄúGermany‚Äù(Alemanha)** apresentaram maior taxa de evas√£o.
- Mulheres tiveram uma leve tend√™ncia maior √† evas√£o em compara√ß√£o √†s mulheres.
- A vari√°vel "Saldo" (balance) sozinha n√£o √© suficiente para prever churn, mas combinada com idade e n√∫mero de produtos, aumenta seu poder preditivo.
- O modelo **XGBoost** foi o que apresentou melhor desempenho entre os algoritmos testados.

---

## üìà Visualiza√ß√µes

- Gr√°fico de barras da evas√£o por localiza√ß√£o (`Geography`)
- Histograma de idade com estratifica√ß√£o por churn
- Gr√°fico de barras do churn por g√™nero
- Matriz de confus√£o dos principais modelos
- Gr√°fico de compara√ß√£o de m√©tricas dos modelos
- Explica√ß√µes locais com LIME para os resultados do modelo XGBoost

---

## üõ†Ô∏è Ferramentas Utilizadas

- **Python** ‚Äì Linguagem principal  
- **Pandas** ‚Äì Manipula√ß√£o e an√°lise de dados  
- **Seaborn / Matplotlib** ‚Äì Visualiza√ß√£o gr√°fica  
- **Scikit-learn** ‚Äì Modelagem preditiva e m√©tricas  
- **Keras / TensorFlow** ‚Äì Constru√ß√£o de rede neural  
- **XGBoost / LightGBM** ‚Äì Modelos de boosting  
- **LIME** ‚Äì Explicabilidade dos modelos  
- **Imbalanced-learn (SMOTE)** ‚Äì Balanceamento de classes  
- **Jupyter Notebook** ‚Äì Ambiente de desenvolvimento  

---

## ‚úÖ Resultados

- O modelo **LightGBM** apresentou as melhores m√©tricas. No entanto, apesar de ter excedido os outros modelos a esse respeito, m√©tricas como **F1-Score** e **recall** se mostraram bem baixas, sendo de **60%** e **52%**, respectivamente, mesmo com a utiliza√ß√£o de SMOTE para balanceamento de classes. 
- Foi utilizada a t√©cnica LIME de IA Explic√°vel para desvendar os fatores que contribuem ou n√£o para o churn de clientes.
- Os fatores que reduzem o risco de churn s√£o: **idade(mais jovem = menor risco)**, **tempo como cliente** e **engajamento como membro ativo**.
- Os fatores que est√£o relacionados com o churn s√£o: **alto sal√°rio**, **saldo elevado (maior poder de trocar de banco)**, **poucos produtos contratados** e **score abaixo da m√©dia(inseguran√ßa para o banco, talvez?**
---

## üíº  Impacto Financeiro do Modelo LightGBM

Ao definir:

- **Receita m√©dia por cliente:** R$ 100,00;
- **M√©trica utilizada:** True Positives (TP) ‚Äî clientes que realmente sairiam, mas foram corretamente identificados pelo modelo;
- **Hip√≥tese:** todos os clientes identificados como TP s√£o retidos com sucesso.

O modelo LightGBM, mesmo com algumas m√©tricas com valor mais baixo do que o desejado (Recall e Precision), mostrou potencial de gerar uma **economia potencial de R$ 32.600,00**

## üß† Conclus√µes

O projeto mostrou como √© poss√≠vel usar **an√°lise de dados e machine learning** para:

- Identificar perfis com maior propens√£o √† evas√£o
- Aplicar t√©cnicas de balanceamento de dados para melhorar a qualidade do modelo
- Avaliar diferentes algoritmos para encontrar o mais adequado ao problema
- Utilizar ferramentas como **LIME** para interpretar decis√µes de modelos complexos

---

## üîÑ Pr√≥ximos Passos

- Implementar modelos em ambiente de produ√ß√£o com monitoramento cont√≠nuo
- Realizar tuning avan√ßado de hiperpar√¢metros via **GridSearch**, **RandomSearch** ou **Bayesian Optimizer** para encontrar melhores m√©tricas **F1-Score** e **Recall**, visto que quando tais m√©tricas est√£o baixas, acaba-se deixando passar falsos positivos e negativos, o que pode representar altos preju√≠zos financeiros para a institui√ß√£o.

---

üßë‚Äçüíª **Autor e Contato**

**Higor Roberto Coutinho Caetano**  
**LinkedIn**: [https://www.linkedin.com/in/higor-caetano-049521136/](https://www.linkedin.com/in/higor-caetano-049521136/)  
**E-mail**: higorfct@gmail.com  
